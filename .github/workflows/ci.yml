name: CI

on:
  push:
    branches: [main]
  pull_request:
    types:
      - opened
      - closed
      - reopened
      - synchronize
      - labeled
      - unlabeled
      - edited
    branches: [main, development]

permissions:
  contents: write
  pull-requests: write

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.ref_name }}
  cancel-in-progress: true

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      python-versions: ${{ steps.get-versions.outputs.python-versions }}
    steps:
    - name: Checkout code
      uses: actions/checkout@v5
    
    - name: Get Python versions from pyproject.toml
      id: get-versions
      run: |
        # Extract Python versions from classifiers
        versions=$(grep -E "Programming Language :: Python :: 3\.[0-9]+" pyproject.toml | \
                  sed -E 's/.*Python :: (3\.[0-9]+).*/\1/' | \
                  sort -V | \
                  jq -R -s -c 'split("\n")[:-1]')
        echo "python-versions=$versions" >> $GITHUB_OUTPUT
        echo "Found Python versions: $versions"

  test:
    name: Run checks and tests
    needs: setup
    strategy:
      fail-fast: false
      matrix:
        python-version: ${{ fromJson(needs.setup.outputs.python-versions) }}
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v5
      with:
        submodules: true

    - name: Set up uv
      uses: astral-sh/setup-uv@v6
      with:
        version: "latest"

    - name: Install dependencies
      run: |
        uv sync --dev --python ${{ matrix.python-version }}

    - name: Run ruff linting
      run: |
        echo "## ðŸ” Ruff Linting Results" >> $GITHUB_STEP_SUMMARY
        if uv run ruff check --output-format=github .; then
          echo "âœ… No linting errors found" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ Linting errors found" >> $GITHUB_STEP_SUMMARY
          exit 1
        fi

    - name: Run ruff formatting check
      run: |
        echo "## ðŸŽ¨ Code Formatting Check" >> $GITHUB_STEP_SUMMARY
        if uv run ruff format --check .; then
          echo "âœ… Code formatting is correct" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ Code formatting issues found" >> $GITHUB_STEP_SUMMARY
          exit 1
        fi

    - name: Run Ty type checking
      run: |
        echo "## ðŸ”§ Ty Type Checking Results" >> $GITHUB_STEP_SUMMARY
        if uv run ty check; then
          echo "âœ… No type errors found" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ Type errors found" >> $GITHUB_STEP_SUMMARY
          exit 1
        fi

    - name: Run tests
      run: |
        if uv run pytest --cov maxx --tb=short -v --junit-xml=pytest.xml; then
          echo '# âœ… Tests passed' >> $GITHUB_STEP_SUMMARY
        else
          echo '# âŒ Tests failed' >> $GITHUB_STEP_SUMMARY
          exit 1
        fi

    - name: Generate test coverage report
      if: (!cancelled())
      run: |
        echo '### Test Coverage Summary' >> $GITHUB_STEP_SUMMARY
        uv run coverage report --show-missing --format=markdown >> $GITHUB_STEP_SUMMARY

    - name: Upload Test Results
      if: (!cancelled())
      uses: actions/upload-artifact@v4
      with:
        name: Test Results (Python ${{ matrix.python-version }})
        path: pytest.xml

  matlab:
    name: Verify path collection with MATLAB
    needs: [test]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v5
        with:
          submodules: true

      - name: Set up MATLAB
        uses: matlab-actions/setup-matlab@v2
        with:
          release: R2025a

      - name: Set up uv
        uses: astral-sh/setup-uv@v6
        with:
          version: "latest"

      - name: Install dependencies
        run: |
          uv sync --all-groups --python 3.12 # MATLAB supports up to Python 3.12

      - name: Run tests
        uses: matlab-actions/run-tests@v2
        with:
          source-folder: tests
          test-results-junit: matlab.xml

      - name: Upload Test Results
        if: (!cancelled())
        uses: actions/upload-artifact@v4
        with:
          name: Test Results (MATLAB path regression)
          path: matlab.xml

  windows:
    name: Run checks and tests on Windows
    needs: setup
    runs-on: windows-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v5
      with:
        submodules: true

    - name: Set up uv
      uses: astral-sh/setup-uv@v6
      with:
        version: "latest"

    - name: Install dependencies
      shell: pwsh
      run: |
        uv sync --dev --python 3.14

    - name: Run ruff linting
      shell: pwsh
      run: |
        "## ðŸ” Ruff Linting Results" | Out-File -Append $env:GITHUB_STEP_SUMMARY
        if (uv run ruff check --output-format=github .) {
          "âœ… No linting errors found" | Out-File -Append $env:GITHUB_STEP_SUMMARY
        } else {
          "âŒ Linting errors found" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          exit 1
        }

    - name: Run ruff formatting check
      shell: pwsh
      run: |
        "## ðŸŽ¨ Code Formatting Check" | Out-File -Append $env:GITHUB_STEP_SUMMARY
        if (uv run ruff format --check .) {
          "âœ… Code formatting is correct" | Out-File -Append $env:GITHUB_STEP_SUMMARY
        } else {
          "âŒ Code formatting issues found" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          exit 1
        }

    - name: Run Ty type checking
      shell: pwsh
      run: |
        "## ðŸ”§ Ty Type Checking Results" | Out-File -Append $env:GITHUB_STEP_SUMMARY
        if (uv run ty check) {
          "âœ… No type errors found" | Out-File -Append $env:GITHUB_STEP_SUMMARY
        } else {
          "âŒ Type errors found" | Out-File -Append $env:GITHUB_STEP_SUMMARY
          exit 1
        }

    - name: Run tests
      shell: pwsh
      run: |
        if (uv run pytest --cov maxx --tb=short -v --junit-xml=pytest.xml) {
          '# âœ… Tests passed' | Out-File -Append $env:GITHUB_STEP_SUMMARY
        } else {
          '# âŒ Tests failed' | Out-File -Append $env:GITHUB_STEP_SUMMARY
          exit 1
        }

    - name: Generate test coverage report
      if: (!cancelled())
      shell: pwsh
      run: |
        '### Test Coverage Summary' | Out-File -Append $env:GITHUB_STEP_SUMMARY
        uv run coverage report --show-missing --format=markdown | Out-File -Append $env:GITHUB_STEP_SUMMARY

    - name: Upload Test Results
      if: (!cancelled())
      uses: actions/upload-artifact@v4
      with:
        name: Test Results (Windows)
        path: windows.xml

  summary:
    runs-on: ubuntu-latest
    needs: [setup, test, matlab, windows]
    if: (!cancelled())
    permissions:
      contents: write
      pull-requests: write
      checks: write
    steps:
      - name: Download Artifacts
        uses: actions/download-artifact@v5
        with:
          path: artifacts

      - name: Publish Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          files: "artifacts/**/*.xml"

      - name: Check all jobs
        run: |
          if [[ "${{ needs.test.result }}" == "success" ]] && [[ "${{ needs.matlab.result }}" == "success" ]] && [[ "${{ needs.windows.result }}" == "success" ]]; then
            echo "âœ… All Python versions passed CI checks"
            echo "## ðŸŽ‰ CI Summary" >> $GITHUB_STEP_SUMMARY
            echo "All tests passed across Python versions: ${{ needs.setup.outputs.python-versions }}" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ Some Python versions failed CI checks"
            echo "## âŒ CI Summary" >> $GITHUB_STEP_SUMMARY
            echo "Some tests failed. Check individual job results for details." >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
